# Bachelor_Thesis
This is the repository of my submission of GermEval21 using Zero and Few-Shot techniques

## Abstract 
In recent years social media platforms like Facebook, Twitter, etc., have gained lots of attention, attracting millions of users who contribute daily on these platforms. The massive amount of data generated by users has made it more and more challenging to deal with all the information present at hand. Therefore, the need for automatic classification of social media texts has risen as it allows us to work against the significant unclassifiable stream of information. This thesis tries to show a solution by working on three different tasks proposed by the Germeval2021 Shared Taskvon the Identification of Toxic, Engaging, and Fact-Claiming Comments. Two approaches are proposed to solve the three tasks of the competition. Firstly, the task is reformulated as a textual entailment problem and then solved by a Zero-Shot Text Classification which tries to classify the text without any labeled training data by relying on the power of pre-trained language models. Secondly, a Few-Shot Text Classification approach is used where small amounts of training data (8, 16, 32, 126, 256) are used. These data-efficient approaches try to open up the field for many other tasks where only limited training data is available, as state-of-the-art systems rely on a vast number of training data.

## Datasets 
To create the datasets run the follwing script:
```
create_dataset.sh
```
## Zero-Shot 
To find the code on Zero-Shot Text Classification use the Notebook germeval_2021.ipynb, for GPU access run on Google Colab

## Few-Shot
Run experiments on all subtasks by executing the follwing command 
```
run_{toxic,engaging,fact}.sh
```

Make sure to have generated all datasets and have an existing Weights and Biases account to visualize the results

### Training the model
use the parameters learning_rate and num_train_epochs to change to different hyperparameter setting in finetune_germeval.py
